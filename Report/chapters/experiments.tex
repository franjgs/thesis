\chapter{Experiments}
\label{chapter:Experiments}

% Experiment settings, dataset, system built, approach, and everything practical goes here

\section{Dataset}
This work focuses on detecting emotional distress amongst the general public from publicly available tweets/blogs. To predict the label for a particular tweet, machine learning models first need to be trained on similar data. This means that availability of a collection of tweets, each having a positive/negative label assigned to it was a prerequisite.\\

Non availability of such data in the beginning of this work led to the following approach - conduct benchmarks and evaluations on a similar problem, and apply the results to build the final system that can perform the said task. Experiments were initially performed on a dataset made available by a machine learning competition website Kaggle \footnote{\url{http://www.kaggle.com/c/detecting-insults-in-social-commentary}}, where the aim is to predict whether a certain piece of text (a comment from a conversation on the internet) can come across as insulting to a user or not. The dataset was a list of 6182 comments, each with a binary label.\\

Preprocessing this text consisted of - cleaning the text (allowing only alphanumeric characters and removing unnecessary punctuation marks), building n-grams of size 2, and using tf-idf information as feature values. Performing these steps resulted in an input matrix consisting of 6182 rows and 23175 columns. Each row corresponds to a distinct comment and each column corresponds to a distinct feature (n-gram, in this case).\\

After the evaluations, the next step in the work required the availability of an unlabelled dataset which could be labelled using crowd intelligence, and which could then finally serve as a basis for the final system to identify emotional distress. This data was fetched from the website Reddit \footnote{\url{http://www.reddit.com}}, which is an online community for people to interact with one another. This website hosts a number of subwebsites called subreddits, two of which were of particular interest - ``/r/happy'' \footnote{\url{http://www.reddit.com/r/happy}} and ``/r/suicidewatch'' \footnote{\url{http:/www.reddit.com/r/suicidewatch}}. The first subreddit is where people submit content if they are feeling happy and want to share their happy moments with others. The second subreddit is where people post when they feel depression, loneliness, feelings of helplessness, and feelings of ending their own lives. On this website, one piece of content is called a ``story'', having a title and a full text. Since the training data is supposed to resemble a tweet in length, only the shorter length ``title'' of the story was selected. Consolidation of dataset from these websites involved downloading and labelling a total of 2000 stories, 1000 each from ``/r/happy'' and ``/r/suicidewatch''. This builds a strong foundation for the system, after which stories are left to be fetched as per a pre-defined crontab schedule, which can be seen in Table~\ref{tab:cron_schedule}.\\

\begin{table}
    \begin{center}
        \begin{tabular}{ | c | c | }
            \hline
            \textbf{Task} & \textbf{Frequency} \\
            \hline
            Fetch 1000 posts from Reddit & 24 hours \\
            \hline
            Fetch 100 tweets from Twitter & 3 hours \\
            \hline
            Re-assign labels to previous tweets and update statistics & 24 hours \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Crontab Schedule}
    \label{tab:cron_schedule}
\end{table}

Finally, the main data for identifying emotional distress is fetched from Twitter. Starting from January 17, Twitter's public streaming API \footnote{\url{https://dev.twitter.com/docs/streaming-apis/streams/public}} was used to fetch 100 tweets every 3 hours, for a total of 800 tweets everyday. Interruptions were faced in this process from February 5 until February 15. This gives an overall view of the general sentiment of the public, on which the analysis was performed.

\section{Approach and Setup}
The work done in this thesis was done in two phases. In the first phase, various machine learning techniques were evaluated, including support vector machines and ensemble learning methods. In the second phase, a system was built that monitors emotional distress on the internet.\\

In the evaluation phase, the comments dataset from Kaggle was used. Bigrams (n-grams of length 2) were extracted and used as features in the vector space representation of comments. To assign values to these features, the tf-idf information as collected from across all comments was used. Once this representation was obtained, the dataset was then evaluated as per k-fold cross validation. To evaluate the performance of a particular model, the model was trained over 90\% of the comments, tested over the remaining 10\%, and the process was repeated 10 times to obtain an average value. This procedure was repeated for standalone support vector machines (using linear, polynomial, gaussian, and RBF kernels) and the ensemble learning methods which include bagging, boosting, and stacking.\\

In the second phase, a web based system was built that is able to identify emotional distress amongst the general public on Twitter, and allow anyone to contribute to the training data (using crowd intelligence). To incorporate crowd intelligence, the appropriate dataset (from Reddit) was downloaded and presented to the users of the system to label. This process resulted in consistent growth of the training data, which in turn improved the machine learning models continuously as and when they were retrained. These models were then used to make a more informed analysis about the level of distress on Twitter.
