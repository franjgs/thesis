\chapter{Experiments}
\label{chapter:Experiments}

% Experiment settings, dataset, system built, approach, and everything practical goes here

\section{Dataset}
This work focuses on detecting emotional distress from publicly available tweets/blogs. To predict the label for a particular tweet, a similar dataset is needed that contains text (where the size of one piece of text is comparable to the size of a single tweet), each having a label corresponding to whether or not the text indicates depression. This dataset comprises the training dataset.

Non availability of such data in the beginning of this work led to explore a slightly different problem in the same domain that operates on a similar dataset. The experiments were initially performed on a dataset made available by a machine learning competition website (\cite{kaggle}), where the aim is to predict whether a certain piece of text (a comment from a conversation on the internet) can be insulting to a user or not. The dataset provided contained the list of comments, each with a binary label. The dataset was split into two parts, the first file containing 3947 comments, while the second one containing 2235 comments.

After conducting experiments on this dataset, the dataset which can finally help towards building a system that can identify emotional distress from the given text was identified and consolidated. Stories from the website Reddit (\cite{reddit}) were downloaded, which is an online community for people to interact with one another, hosting two main subreddits of interest - the subreddit where people post if in case they are planning to end their lives (\cite{reddit_suicidewatch}), and the subreddit where people post if in case they want to share their happy moments with others (\cite{reddit_happy}). The process of building the dataset was integrated in the main web interface, and every time there is a request to increase the size of the dataset, 500 stories from each of the subreddits mentioned are downloaded and stored in the database. Since this system also aims to incorporate crowd intelligence into the system (letting people assign labels to the training data), 2000 stories are initially labelled manually to build a strong foundation for the system, after which stories are left to be labelled on demand.

To actually incorporate identifying emotional distress into our system, the main data is fetched from Twitter. Twitter's public streaming API (\cite{twitter_streaming_api}) is used to fetch 100 tweets every 3 hours, hence fetching 800 tweets every single day (interruptions in this process were faced from February 5 until February 15). This gives an overall view of the general sentiment of the public, on which the analysis is performed.

To summarize, the first part of the training data (comments on the web) comes from a competition on Kaggle, the second part comes from Reddit (main title of the stories posted by users), and the actual data for prediction comes from Twitter.

\section{Approach and Setup}
Various machine learning techniques are experimented with and evaluated, including standalone support vector machines, multiple kernel learning algorithms, and finally ensemble learning methods. This work can broadly be seen as being done in two phases. In the first phase, the learning techniques are evaluated using cross validation. In the second phase, a system is built that monitors emotional distress on the internet.

In the first phase, the comments \cite{kaggle} dataset is used, constructting n-grams (of length 2) and then obtaininign the vector space representation for each comment along with the label for each. This data is now split into training and test data as per holdout cross validation. The model is then trained on the training data, and the predictions are obtained for the testing data. Since the actual predictions of the testing data are already known, the accuracy of the classifier thus trained is obtained. A 70-30 split on the data is performed, i.e. 70\% of the data is used to train the models, and the remaining 30\% is used to calculate predictions with.

This procedure is repeated for standalone support vector machines (using linear, polynomial, gaussian, and RBF kernels), multiple kernel learning methods, and the ensemble learning methods which include bagging, boosting, and stacking. The calculated accuracy for each method is then reported.

In the second phase, the system that is able to monitor public content (with focus on fetching content from Twitter) and identify the tweets which may signal emotional distress is implemented.

\section{System Details}
The final output of this work is a web based system that allows users to -
\begin{itemize}
    \item{assign labels to stories fetched from Reddit, which helps in building up a larget set of training data, as well as tapping into crowd intelligence}
    \item{monitor a general \emph{level of distress} amongst people who are posting on Twitter, grouped by date}
    \item{keep a check on certain tweets that have been classified by the model as depressed}
\end{itemize}

The system mainly comprises of two modules - \emph{ratings}, and \emph{monitor}.

\subsection{Ratings}
The \emph{ratings} module is responsible for allowing users to help build the training data. As mentioned before, the main source of text is Reddit. Stories fetched are simply stored in the database. When a user chooses to visit the ratings module, he/she is presented with the next story that does not have a label. The user can then proceed to assign a positive (depressed) or a negative (not depressed) label to it, which is then stored in the database.
