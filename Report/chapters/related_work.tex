\chapter{Related Work}
\label{chapter:Related Work}

The work presented in this thesis belongs to the domain of document classification and sentiment analysis, both of which have been well researched. A summary of some of the main approaches to document categorization based on their content was presented in \cite{sebastiani2002machine}. This work also presented a discussion about representing documents in such problems (approaches similar to building n-grams), building classifiers that can perform this categorization, as well as discussing how to evaluate such classifiers. Using n-grams to classify documents was described in \cite{cavnar1994n}, achieving an accuracy as high as 99.8\% in one particular test involving classifying documents of length more than 300 and selecting the top 400 n-grams. However, in documents of length less than 300 bytes and selecting the top 100 n-grams yielded an accuracy of 92.9\%.

Much of the research done in the field of sentiment analysis has been summarized in \cite{pang2008opinion}, covering techniques that can be used to build systems that can enable information retrieval in opinionated data. The work done by \cite{pang2002thumbs} concludes that sentiment analysis is a much more challenging problem than simple text classification, and classifiers that perform well in text classification usually perform worse when it comes to sentiment analysis. For classification of movie review data from IMDB, they were able to obtain a cross validation accuracy of 82.7\% using an SVM. Much of the research in this field focuses on full scale text documents, and not so much on microblogging platforms. One such work is \cite{pak2010twitter} which presents a linguistic analysis (for the purposes of sentiment mining) of data collected from Twitter.

Support vector machines have been found to be highly successful in text classification problems mainly because of their ability to handle a large number of sparse features. This has been addressed theoretically in \cite{joachims2002learning}, including thorough explanations of document representations as well as efficient algorithms for training SVMs. An early analysis of the use of support vector machines in text categorization problems can be found in \cite{joachims1998text} and \cite{drucker1999support}. For the problem that \cite{drucker1999support} addressed (classifying emails as spam or not), SVMs provided the best performance when using binary features, and also took significantly less training time as compared to another model presenting comparable performance. \cite{manevitz2002one} addressed the problem of categorizing the \emph{Reuters} dataset \cite{reuters}, using the tf-idf representation for documents. \cite{hsu2003practical} presents a software implentation of support vector machines as well as a guide to effectively using them. The implementation from this work is also (indirectly) used in the system presented in Section~\ref{section:system_details}

A lot of the research in ensemble learning focuses on creating ensembles out of decision trees. Various reasons behind the fact that a combination (ensemble) of models can outperform a single classifier are covered in \cite{valentini2002ensembles}. Bagging, first proposed in \cite{breiman1996bagging}, is an algorithm that is well suited for addressing variance problems. Bagged ensembles of support vector machines for analyzing gene expression data are built and used in the work done by \cite{valentini2003bagged}, where it is observed that such ensembles achieve better or equal classification accuracy with respect to a single SVM. Much of the work done in ensemble learning focuses on constructing ensembles using decision trees as the underlying models. As noted in \cite{bauer1999empirical}, the performance of boosting is not uniformly better for \emph{all} datasets. AdaBoost, short for Adaptive Boosting was first introduced in \cite{freund1999short}, and was found to be performing better than using individual classifiers by \cite{bloehdorn2004text} when tested on the \emph{Reuters} \cite{reuters} corpus. Stacking \cite{wolpert1992stacked} is another ensemble learning method that has been studied extensively. \cite{dvzeroski2004combining} conclude that a stacking ensemble performs equally as good as the best individual classifier in the ensemble.

Even though not a lot of work has been done yet in applying ensemble learning to classify on data extracted from Twitter, text classification on Twitter has seen a lot of activity in the recent times. Works including \cite{sriram2010short}, \cite{go2009twitter}, and \cite{jiang2011target} investigate the problem of identifying the sentiment of a tweet based on its content. While \cite{sriram2010short} focuses on assigning a particular tweet one out of five categories (news, opinions, deals, events, and private messages), \cite{go2009twitter} investigate the issues faced in assigning a binary sentiment (positive or negative) to a tweet in regards to a particular query term, achieving an accuracy of above 80\% when including emoticons data. In spite of the fact that a tremendous amount of work has been done on identifying sentiments on Twitter, not a lot of visible work was found that addressed specifically the problem of finding out tweets displaying depressive emotions.
