\chapter{Related Work}
\label{chapter:Related Work}

The work presented in this thesis falls under the combined domain of document classification and sentiment analysis, both of which have been very well researched. A summary of some of the main approaches to document categorization based on their content was presented in \cite{sebastiani2002machine}. This work also discussed representing documents in such problems (approaches similar to building n-grams), building classifiers that can perform this categorization, as well as how to evaluate such classifiers. Some work that used n-grams to build a document classifier was presented in \cite{cavnar1994n}, wherein an accuracy as high as 99.8\% was achieved (in one particular test involving classifying documents of length more than 300 and selecting the top 400 n-grams). However, documents of length less than 300 bytes and selecting the top 100 n-grams yielded an accuracy of 92.9\%.

Much of the research done in the field of sentiment analysis has been summarized in \cite{pang2008opinion}, which also covers techniques that can be used to build systems that can enable information retrieval in opinionated data. The work done by \cite{pang2002thumbs} concludes that sentiment analysis is a much more challenging problem than simple text classification, and classifiers that perform well in text classification usually perform worse when it comes to sentiment analysis. For classification of movie review data from IMDB, they were able to obtain a cross validation accuracy of 82.7\% using a linear-kernel SVM. Much of the research in this field focuses on full scale text documents, but not so much on microblogging platforms. Although one such work is \cite{pak2010twitter}, presenting a linguistic analysis (for the purposes of sentiment mining) of data collected from Twitter.

Support vector machines have been found to be highly successful in text classification problems mainly because of their ability to handle a large number of sparse features. This has been addressed theoretically in \cite{joachims2002learning}, including thorough explanations of document representation as well as efficient algorithms for training SVMs. An early analysis of the use of support vector machines in text categorization problems can be found in \cite{joachims1998text} and \cite{drucker1999support}. For the problem that \cite{drucker1999support} addressed (classifying emails as spam or not), SVMs provided the best performance when using binary features, and also took significantly less training time as compared to another model presenting comparable performance. The problem of categorizing the \emph{Reuters} \cite{reuters} dataset was also addressed in \cite{manevitz2002one}, wherein documents were represented using the tf-idf representation. From a practical perspective, \cite{hsu2003practical} presents a software implentation of support vector machines as well as a guide to effectively using them. Their implementation is (indirectly) used in the system presented in Section~\ref{section:system_details}

A lot of the research in ensemble learning focuses on creating ensembles out of decision trees (summarized in \cite{safavian1991survey}). The reasons behind the fact that a combination (ensemble) of models can outperform a single classifier are covered in \cite{valentini2002ensembles}. Bagging, first proposed in \cite{breiman1996bagging}, is well suited for addressing variance problems. Bagged ensembles of support vector machines for analyzing gene expression data are built and used in the work done by \cite{valentini2003bagged}, where it is observed that such ensembles achieve better or equal, if not worse, classification accuracy with respect to a single SVM. As noted in \cite{bauer1999empirical}, the performance of boosting is not uniformly better for \emph{all} datasets. AdaBoost, short for Adaptive Boosting was first introduced in \cite{freund1999short}, and was found to be performing better than using individual classifiers by \cite{bloehdorn2004text} when tested on the \emph{Reuters} \cite{reuters} corpus. Stacking \cite{wolpert1992stacked} is another ensemble learning method that has been studied extensively. \cite{dvzeroski2004combining} conclude that a stacking ensemble performs equally as good as the best individual classifier in the ensemble.

Even though not a lot of work has been done in applying ensemble learning to perform classification on data extracted from microblogging websites, text classification on Twitter has seen a lot of activity in the recent times. Works including \cite{sriram2010short}, \cite{go2009twitter}, and \cite{jiang2011target} thoroughly investigate the problem of identifying the sentiment of a tweet based on its content. While \cite{sriram2010short} focuses on putting tweet in one out of five categories (news, opinions, deals, events, and private messages), \cite{go2009twitter} investigates the issues faced in assigning a binary sentiment (positive or negative) to a tweet in regards to a particular query term, achieving an accuracy of above 80\% when including emoticons data. In spite of the fact that a tremendous amount of work has been done on identifying sentiments on Twitter, not a lot of visible work was found that addressed specifically the problem of finding out tweets displaying depressive emotions.
